# Learning Outcomes Architecture
**AI Acceleration: AI Tools for Real Estate Professionals**

**Course:** Williamson County Association of REALTORS
**Duration:** 9:00 AM - 4:00 PM (7 hours instructional time)
**Date:** [TBD]
**Instructor:** Ryan, Build Things that Build Things
**Document Version:** 1.0

---

## Executive Summary

This document defines the comprehensive learning outcomes architecture for AI Acceleration, mapping specific, measurable learning objectives to Bloom's taxonomy levels and real estate industry applications. The outcomes are designed to transform real estate professionals from AI-curious to AI-capable within a single intensive workshop, with immediate workplace application.

**Course-Level Goal:** Enable real estate professionals to confidently integrate AI tools into their daily workflows, saving 5-10 hours weekly while maintaining professional standards and regulatory compliance.

**Pedagogical Approach:** Adult learning principles with 70% hands-on practice, scaffolded progression from confidence-building to competence development to transfer preparation.

**Assessment Philosophy:** Formative feedback throughout (low-stakes practice) culminating in authentic performance tasks (real work outputs) rather than traditional testing.

---

## Course-Level Learning Outcomes

By the end of AI Acceleration, participants will be able to:

### 1. **Generate Professional Real Estate Content Using AI**
- **Bloom's Level:** Apply (Level 3)
- **Measurement:** Successfully create property descriptions, client emails, and social media content meeting professional standards
- **Business Impact:** 5-10 hours weekly time savings on writing and marketing coordination
- **Success Criteria:** 90%+ of participants produce usable AI-generated content during workshop

### 2. **Evaluate AI Outputs for Accuracy, Compliance, and Brand Alignment**
- **Bloom's Level:** Evaluate (Level 5)
- **Measurement:** Identify and correct AI errors, compliance risks, and off-brand language in sample outputs
- **Business Impact:** Mitigate Fair Housing Act violations and maintain professional reputation
- **Success Criteria:** 80%+ pass Fair Housing compliance quiz (5/6 correct on real-world scenarios)

### 3. **Design Effective Prompts Through Iterative Refinement**
- **Bloom's Level:** Create (Level 6)
- **Measurement:** Write prompts from scratch that produce high-quality outputs with minimal editing
- **Business Impact:** Faster content creation with better first-draft quality
- **Success Criteria:** Participants demonstrate 3-iteration improvement cycle on own content

### 4. **Select Appropriate AI Tools for Specific Real Estate Tasks**
- **Bloom's Level:** Analyze (Level 4)
- **Measurement:** Match tools to job-to-be-done using decision criteria (time savings, integration, privacy, cost)
- **Business Impact:** Avoid tool bloat while maximizing productivity gains
- **Success Criteria:** Correctly select tools for 4/5 scenario-based challenges

### 5. **Implement AI-Enhanced Workflows in Daily Real Estate Practice**
- **Bloom's Level:** Apply (Level 3)
- **Measurement:** Create personalized 30-day implementation plan with specific workflows and success metrics
- **Business Impact:** Sustained adoption and measurable productivity improvement
- **Success Criteria:** 60%+ of participants actively using AI tools 30 days post-workshop

---

## Module-Level Learning Outcomes

### Module 1: Welcome & Framing (9:00-9:10, 10 minutes)

**Learning Objectives:**
- **LO 1.1:** Articulate personal goals for AI adoption in real estate practice
  - **Bloom's Level:** Understand (Level 2)
  - **Assessment:** Opening pulse - verbal sharing of top 3 priorities

- **LO 1.2:** Recognize the "outcomes over hype" and "ship small" mental framework
  - **Bloom's Level:** Remember (Level 1)
  - **Assessment:** Recall house rules when prompted

**Success Criteria:**
- Each participant identifies at least 1 specific job they want AI to help with
- Group captures 5-7 priority use cases on whiteboard

**Assessment Method:**
- Formative: Live whiteboard capture during Q&A pulse
- Observable: Engagement and specificity of stated goals

**Real Estate Use Case:**
- Prioritizing which time-draining tasks to automate first (lead follow-up, listing prep, market analysis, etc.)

---

### Module 2: Opening Q&A Pulse (9:10-9:30, 20 minutes)

**Learning Objectives:**
- **LO 2.1:** Identify the highest-impact AI applications for individual practice needs
  - **Bloom's Level:** Analyze (Level 4)
  - **Assessment:** Self-identify top 2 jobs to automate

- **LO 2.2:** Compare personal pain points with peer experiences
  - **Bloom's Level:** Understand (Level 2)
  - **Assessment:** Participate in dot-voting exercise

**Success Criteria:**
- Group consensus on 5-7 priority jobs to address during workshop
- Each participant identifies personal "quick win" opportunity

**Assessment Method:**
- Formative: Whiteboard poll and dot-voting
- Observable: Quality of use case articulation

**Real Estate Use Case:**
- Diagnosing which bottlenecks in transaction workflow are AI-addressable vs. requiring human judgment

---

### Module 3: Mental Models for AI (9:30-9:55, 25 minutes)

**Learning Objectives:**
- **LO 3.1:** Explain AI using accessible mental models (smart assistant, pattern matcher, autocomplete)
  - **Bloom's Level:** Understand (Level 2)
  - **Assessment:** Teach-back to partner using analogies

- **LO 3.2:** Apply "trust-but-verify" principle to AI outputs
  - **Bloom's Level:** Apply (Level 3)
  - **Assessment:** Identify verification steps in sample workflow

- **LO 3.3:** Recognize "context over cleverness" as key to AI effectiveness
  - **Bloom's Level:** Understand (Level 2)
  - **Assessment:** Explain why detailed prompts outperform vague ones

- **LO 3.4:** Adopt MOODA (Minimum Outcome, Obvious Difficulty, Accelerate) iterative mindset
  - **Bloom's Level:** Apply (Level 3)
  - **Assessment:** Describe iteration cycle for improving AI output

**Success Criteria:**
- Participants can explain AI in plain language to clients/colleagues
- Recognize iteration as normal process, not failure
- Identify when human verification is required

**Assessment Method:**
- Formative: Think-pair-share exercise
- Observable: Quality of peer explanations during debrief

**Real Estate Use Case:**
- Understanding why AI can draft listing descriptions but shouldn't make pricing decisions
- Framing AI as amplifying top producer knowledge across entire team

---

### Module 4: What AI Is / Isn't (9:55-10:25, 30 minutes)

**Learning Objectives:**
- **LO 4.1:** Distinguish between AI as "word engine" vs. "truth engine"
  - **Bloom's Level:** Understand (Level 2)
  - **Assessment:** Spot the hallucination exercise (identify false property features)

- **LO 4.2:** Identify strong-fit AI applications (drafts, rewrites, summaries, variations)
  - **Bloom's Level:** Analyze (Level 4)
  - **Assessment:** Categorize 10 real estate tasks as strong/weak AI fits

- **LO 4.3:** Recognize weak-fit AI applications requiring provided facts or human judgment
  - **Bloom's Level:** Analyze (Level 4)
  - **Assessment:** Flag 5 scenarios where AI should not be used alone

- **LO 4.4:** Perform basic AI tasks (email rewrite, PDF summarization)
  - **Bloom's Level:** Apply (Level 3)
  - **Assessment:** Live demo follow-along - rewrite email and summarize CMA

**Success Criteria:**
- 80%+ correctly identify AI fit/misfit scenarios
- Successfully complete 2 live demo exercises
- Articulate at least 2 AI limitations

**Assessment Method:**
- Formative: "Spot the fit/misfit" card sort exercise
- Performance: Live follow-along during demo
- Observable: Accuracy of categorization task

**Real Estate Use Case:**
- AI excels: Transforming bullet points into compelling listing descriptions
- AI struggles: Determining fair market value without provided comps
- AI fails: Negotiation strategy requiring reading emotional cues

---

### Module 5: Prompting Fundamentals (10:35-11:10, 35 minutes)

**Learning Objectives:**
- **LO 5.1:** Construct prompts with clear asks, audience, channel, essential facts, and style constraints
  - **Bloom's Level:** Create (Level 6)
  - **Assessment:** Prompting Checklist drill - transform vague to specific

- **LO 5.2:** Apply iteration phrases to refine AI outputs ("tighten," "add," "remove," "rewrite as")
  - **Bloom's Level:** Apply (Level 3)
  - **Assessment:** 3-iteration improvement cycle on own content

- **LO 5.3:** Specify formatting requirements and exclusions ("do not say" lists)
  - **Bloom's Level:** Apply (Level 3)
  - **Assessment:** Add 3 constraints + 2 exclusions to base prompt

- **LO 5.4:** Use prompting templates for common real estate tasks
  - **Bloom's Level:** Apply (Level 3)
  - **Assessment:** Fill template and generate usable output

**Success Criteria:**
- Prompts include all 5 elements: audience, channel, facts, style, exclusions
- Demonstrate measurable improvement from v1 to v3 output
- Generate production-ready content using templates

**Assessment Method:**
- Formative: 3 mini-drills with peer feedback
  - Drill 1: Clarity Pass (5 elements present)
  - Drill 2: Constraint Layering (3 constraints + 2 exclusions)
  - Drill 3: Iteration (v1 → v3 improvement)
- Rubric: 5 points (1 per element)

**Real Estate Use Case:**
- Drill 1: Transform "help me write a listing" into prompt with buyer persona, property facts, tone, exclusions
- Drill 2: Add constraints (150 words max, professional tone, school zone mention) and exclusions (no unverifiable claims, no Fair Housing risks)
- Drill 3: Improve listing description through iteration commands

---

### Module 6: Context Engineering (11:10-11:50, 40 minutes)

**Learning Objectives:**
- **LO 6.1:** Create a personalized "Voice & Tactics" context card
  - **Bloom's Level:** Create (Level 6)
  - **Assessment:** Complete all template fields with specific details

- **LO 6.2:** Document brand voice pillars and taboo phrases
  - **Bloom's Level:** Apply (Level 3)
  - **Assessment:** 3 voice attributes + 5 "do not say" phrases listed

- **LO 6.3:** Map common objections to one-line rebuttals
  - **Bloom's Level:** Apply (Level 3)
  - **Assessment:** 5 buyer/seller objections with responses documented

- **LO 6.4:** Encode local market nuance (school zones, commute, HOA quirks)
  - **Bloom's Level:** Apply (Level 3)
  - **Assessment:** 3 micro-geography details specific to Williamson County

- **LO 6.5:** Integrate context card into prompt workflow
  - **Bloom's Level:** Apply (Level 3)
  - **Assessment:** Use context card as prompt prefix in live exercise

**Success Criteria:**
- Complete, specific context card (not generic/vague)
- Demonstrable voice consistency in AI outputs
- Shareback shows personality and local expertise

**Assessment Method:**
- Deliverable: 1-page Voice & Tactics Card (fillable template)
- Formative: Pair exercise - partners review for completeness/specificity
- Performance: 3 volunteers shareback outputs for instructor punch-ups

**Real Estate Use Case:**
- Voice: "Warm but data-driven," "Conversational not salesy," "Luxury without pretension"
- Taboo: "Act now!", "Won't last!", "Dream home," demographic descriptors
- Objections: "Why list now in slow market?" → "Motivated buyers shopping now face less competition"
- Local: "Ravenwood High district," "I-65 commute 25 min to Nashville," "Spring Hill HOA allows home businesses"

---

### Module 7: Rapid Sharebacks (11:50-12:00, 10 minutes)

**Learning Objectives:**
- **LO 7.1:** Present AI-generated work to peers
  - **Bloom's Level:** Apply (Level 3)
  - **Assessment:** Volunteer reads output aloud

- **LO 7.2:** Receive and incorporate expert feedback on AI outputs
  - **Bloom's Level:** Evaluate (Level 5)
  - **Assessment:** Identify improvement opportunities from instructor punch-ups

**Success Criteria:**
- 3 volunteers share outputs
- Group identifies 2-3 improvement patterns applicable to all

**Assessment Method:**
- Formative: Live peer feedback and instructor coaching
- Observable: Volunteer confidence and output quality

**Real Estate Use Case:**
- Compare 3 different approaches to same listing using context cards
- Identify common gaps (missing compliance, weak CTA, generic language)

---

### Module 8: Identify Top Jobs (1:00-1:35, 35 minutes)

**Learning Objectives:**
- **LO 8.1:** Conduct organization-wide job inventory across 9 domains
  - **Bloom's Level:** Analyze (Level 4)
  - **Assessment:** Complete job scan worksheet (domains: lead intake, appointment setting, CRM hygiene, transaction tasks, market intel, customer service, FAQs, ops coordination, comp/listing scans)

- **LO 8.2:** Evaluate jobs using selection criteria (minutes/week, pain level, risk, measurable outcome)
  - **Bloom's Level:** Evaluate (Level 5)
  - **Assessment:** Score each job on 4 criteria

- **LO 8.3:** Prioritize 2 pilot jobs for AI implementation
  - **Bloom's Level:** Evaluate (Level 5)
  - **Assessment:** Select 2 jobs saving ≥30 min/week with low risk

- **LO 8.4:** Define success metrics for pilot jobs
  - **Bloom's Level:** Create (Level 6)
  - **Assessment:** Write measurable outcome for each pilot (time saved, quality proxy)

**Success Criteria:**
- Systematic evaluation of ≥5 potential AI jobs
- 2 pilot jobs selected with clear success metrics
- At least 1 pilot extends beyond marketing/writing

**Assessment Method:**
- Deliverable: Job-Scan Worksheet with scoring
- Formative: Dot-vote exercise - group prioritization
- Observable: Depth of analysis (not just "listings and emails")

**Real Estate Use Case:**
- Lead intake/triage: Extract budget, timing, must-haves from inquiry email
- Appointment setting: Draft calendar invite with showing details
- CRM hygiene: Summarize long email threads into CRM note
- Transaction micro-tasks: Extract key dates from purchase agreement
- Market intel: Condense 20-page market report into 5 seller bullets
- Customer service: Draft response to "How's my house search going?"
- FAQs: Generate answers to "What's the commission structure?"
- Ops coordination: Create task list from closing checklist
- Comp scans: Summarize 10 comparable sales into narrative

---

### Module 9: Finding Tools (1:35-2:00, 25 minutes)

**Learning Objectives:**
- **LO 9.1:** Select AI tools using job-to-be-done framework (text, images, utilities)
  - **Bloom's Level:** Analyze (Level 4)
  - **Assessment:** Match 5 jobs to appropriate tool categories

- **LO 9.2:** Apply filtering criteria (saves minutes now, easy to edit, privacy posture, cost clarity, workflow integration)
  - **Bloom's Level:** Evaluate (Level 5)
  - **Assessment:** Score 3 tools against 5 criteria using decision tree

- **LO 9.3:** Maintain a minimal, effective tool stack
  - **Bloom's Level:** Evaluate (Level 5)
  - **Assessment:** Justify tool choices (avoid bloat)

- **LO 9.4:** Assess privacy and security implications of tool selection
  - **Bloom's Level:** Evaluate (Level 5)
  - **Assessment:** Flag tools inappropriate for client PII

**Success Criteria:**
- Select 1-3 tools matching personal workflow needs
- Justify selections with specific criteria
- Identify at least 1 privacy risk to avoid

**Assessment Method:**
- Formative: Decision tree walkthrough for each pilot job
- Deliverable: Tool selection with written justification
- Observable: Reasoning quality (not just "everyone uses ChatGPT")

**Real Estate Use Case:**
- Text generation: ChatGPT (free) vs. Claude (better tone) vs. Writer.Homes (real estate-specific)
- Light images: Virtual Staging AI vs. Canva AI
- Utilities: Desktop AI app for PDF/screenshot processing
- Privacy: Enterprise ChatGPT for client data vs. free tier for generic content

---

### Module 10: AI Security & Fraud Awareness (2:10-2:40, 30 minutes)

**Learning Objectives:**
- **LO 10.1:** Detect AI-generated fraud across 4 vectors (text, voice, images, documents)
  - **Bloom's Level:** Evaluate (Level 5)
  - **Assessment:** 6-item checklist quiz on realistic fakes (pass ≥5/6)

- **LO 10.2:** Apply "verify via known channels" protocol for suspicious communications
  - **Bloom's Level:** Apply (Level 3)
  - **Assessment:** Describe verification workflow for wire instruction change

- **LO 10.3:** Identify red flags in AI-manipulated content
  - **Bloom's Level:** Analyze (Level 4)
  - **Assessment:** Spot manipulation in 4 demo scenarios

- **LO 10.4:** Implement disclosure requirements for AI-enhanced marketing materials
  - **Bloom's Level:** Apply (Level 3)
  - **Assessment:** Label virtually staged photos appropriately

**Success Criteria:**
- 80%+ pass fraud detection quiz
- Articulate verification workflow without prompting
- Correctly flag 3/4 fraud demos

**Assessment Method:**
- Summative: 6-item checklist quiz (realistic scenarios)
- Formative: Live discussion during 4 red-flag demos
- Observable: Skepticism and verification instinct demonstrated

**Real Estate Use Case:**
- **Text fraud:** Phishing email from "title officer" requesting wire change - verify via known phone number
- **Voice fraud:** Cloned voicemail from "broker" about urgent showing - callback to verified number
- **Image fraud:** "Repaired" listing photo with cloned elements - identify lens inconsistencies
- **Document fraud:** Altered purchase addendum - request original via known channel, check hash

---

### Module 11: Desktop AI + Connectors (2:40-3:25, 45 minutes)

**Learning Objectives:**
- **LO 11.1:** Use hotkey workflow to invoke AI on screenshots, PDFs, photos, audio
  - **Bloom's Level:** Apply (Level 3)
  - **Assessment:** Successfully complete 3 file-type workflows

- **LO 11.2:** Extract structured information from unstructured files
  - **Bloom's Level:** Apply (Level 3)
  - **Assessment:** Pull 7 key fields from sample PDF/image

- **LO 11.3:** Transform file contents into actionable outputs (summaries, replies, task lists)
  - **Bloom's Level:** Apply (Level 3)
  - **Assessment:** Generate output meeting quality rubric

- **LO 11.4:** Integrate file-drop workflow into existing real estate processes
  - **Bloom's Level:** Apply (Level 3)
  - **Assessment:** Describe how workflow fits daily routine

**Success Criteria:**
- Complete all 3 demo workflows successfully
- Extract accurate information from files
- Generate usable outputs (not just "it worked")

**Assessment Method:**
- Performance: Live task completion
  - Flow 1: Drop 20-page market PDF → 5 bullets + 1 "why it matters"
  - Flow 2: Drop listing photos → AI extracts features → MLS-safe draft
  - Flow 3: Drop email thread screenshot → concise reply + task list
- Rubric: Accuracy (3), completeness (3), usability (2)

**Real Estate Use Case:**
- Market PDF: Extract median price trend, DOM, inventory change, list-to-sale ratio, seller insight
- Listing photos: Identify beds, baths, features, condition notes
- Email thread: Summarize client's changing requirements and next steps

---

### Module 12: Capstone Sprint (3:25-3:55, 30 minutes)

**Learning Objectives:**
- **LO 12.1:** Synthesize all workshop skills into complete AI-enhanced workflow
  - **Bloom's Level:** Create (Level 6)
  - **Assessment:** Build complete pack for 1 pilot job

- **LO 12.2:** Create reusable AI assets (prompt file, context card, samples, measurement plan)
  - **Bloom's Level:** Create (Level 6)
  - **Assessment:** Deliverable meets 5-part rubric

- **LO 12.3:** Demonstrate compliance and quality control in AI workflow
  - **Bloom's Level:** Evaluate (Level 5)
  - **Assessment:** Verification steps documented

- **LO 12.4:** Design measurement approach for AI implementation success
  - **Bloom's Level:** Create (Level 6)
  - **Assessment:** Metrics track time saved and quality proxy

**Success Criteria:**
- Complete pack includes: prompt file, context card, 2 sample inputs, 2 verified outputs, measurement plan
- Quality rubric: clarity (2), context (2), safety/compliance (2), measurable outcome (2), repeatability (2) = 10 points total
- Score ≥7/10 indicates readiness for Monday implementation

**Assessment Method:**
- Summative: Capstone Pack deliverable evaluated against rubric
- Components required:
  1. Prompt file (saved template ready to reuse)
  2. Context Card (voice, constraints, objections, local details)
  3. 2 sample inputs (real content from participant's practice)
  4. 2 verified outputs (AI-generated, human-reviewed, production-ready)
  5. Measurement plan (minutes saved, quality metric)

**Real Estate Use Case:**
- Example pilot: Price-reduction email to sellers
  - Prompt: Include comps, handle "wait for right buyer" objection, offer 2 meeting times
  - Context: Empathetic tone, data-led, avoid pressure tactics
  - Inputs: 2 different properties needing price adjustments
  - Outputs: Professional emails ready to send
  - Metrics: 20 minutes saved per email, client response rate tracked

---

### Module 13: Commitments & Next Steps (3:55-4:00, 5 minutes)

**Learning Objectives:**
- **LO 13.1:** Commit to specific AI implementation within 48 hours
  - **Bloom's Level:** Apply (Level 3)
  - **Assessment:** Public verbal commitment to group

- **LO 13.2:** Access post-workshop resources (QR, handouts, support channels)
  - **Bloom's Level:** Remember (Level 1)
  - **Assessment:** Scan QR and bookmark resources

- **LO 13.3:** Establish accountability partnership for 30-day adoption
  - **Bloom's Level:** Apply (Level 3)
  - **Assessment:** Exchange contact info with accountability buddy

**Success Criteria:**
- 100% of participants state specific first action
- All participants have resource access
- Buddy pairs established for follow-up

**Assessment Method:**
- Observable: Public commitment (popcorn-style sharing)
- Deliverable: QR scan confirmation, buddy contact exchange
- Follow-up: 30-day survey tracking implementation

**Real Estate Use Case:**
- Commitment examples:
  - "Monday morning: Use AI to write listing for 123 Main St"
  - "This week: Create context card and test on 3 client emails"
  - "Next 7 days: Build lead intake triage prompt and run on 5 inquiries"

---

## Learning Outcomes Alignment Matrix

| Module | Time | Learning Outcome | Bloom's Level | Assessment Method | Real Estate Use Case | Priority |
|--------|------|------------------|---------------|-------------------|---------------------|----------|
| 1. Welcome & Framing | 9:00-9:10 | Articulate personal AI goals | Understand | Opening pulse verbalization | Identify top time drains to automate | MVP |
| 2. Opening Q&A Pulse | 9:10-9:30 | Identify highest-impact AI applications | Analyze | Whiteboard dot-voting | Prioritize which jobs to pilot | MVP |
| 3. Mental Models | 9:30-9:55 | Explain AI using accessible analogies | Understand | Teach-back to partner | Frame AI for clients/colleagues | MVP |
| 3. Mental Models | 9:30-9:55 | Apply trust-but-verify principle | Apply | Workflow verification steps | Know when to fact-check AI | MVP |
| 4. What AI Is/Isn't | 9:55-10:25 | Distinguish word engine vs. truth engine | Understand | Spot the hallucination exercise | Recognize AI limitations | MVP |
| 4. What AI Is/Isn't | 9:55-10:25 | Identify strong/weak AI fits | Analyze | Categorize 10 tasks as fit/misfit | Choose appropriate AI tasks | MVP |
| 4. What AI Is/Isn't | 9:55-10:25 | Perform basic AI tasks | Apply | Live demo follow-along | Rewrite email, summarize PDF | MVP |
| 5. Prompting Fundamentals | 10:35-11:10 | Construct complete prompts | Create | 3 mini-drills with rubric | Write listing description prompt | MVP |
| 5. Prompting Fundamentals | 10:35-11:10 | Apply iteration phrases | Apply | v1→v3 improvement cycle | Refine AI outputs to quality | MVP |
| 5. Prompting Fundamentals | 10:35-11:10 | Specify formatting & exclusions | Apply | Add constraints drill | Control output format and safety | MVP |
| 6. Context Engineering | 11:10-11:50 | Create Voice & Tactics context card | Create | Complete template deliverable | Document brand voice for consistency | MVP |
| 6. Context Engineering | 11:10-11:50 | Map objections to rebuttals | Apply | 5 objection-response pairs | Handle common buyer/seller concerns | MVP |
| 6. Context Engineering | 11:10-11:50 | Encode local market nuance | Apply | 3 micro-geography details | Leverage Williamson County expertise | MVP |
| 7. Rapid Sharebacks | 11:50-12:00 | Present AI work to peers | Apply | Volunteer shareback | Build confidence sharing outputs | Enhancement |
| 8. Identify Top Jobs | 1:00-1:35 | Conduct org-wide job inventory | Analyze | Job scan worksheet | Systematically identify AI opportunities | MVP |
| 8. Identify Top Jobs | 1:00-1:35 | Evaluate jobs with criteria | Evaluate | Scoring on 4 dimensions | Select highest-ROI pilot jobs | MVP |
| 8. Identify Top Jobs | 1:00-1:35 | Prioritize 2 pilot jobs | Evaluate | Select ≥30 min/week saved | Focus implementation efforts | MVP |
| 8. Identify Top Jobs | 1:00-1:35 | Define success metrics | Create | Measurable outcomes written | Track AI implementation value | MVP |
| 9. Finding Tools | 1:35-2:00 | Select tools by job-to-be-done | Analyze | Match 5 jobs to tool types | Choose right tool for task | MVP |
| 9. Finding Tools | 1:35-2:00 | Apply filtering criteria | Evaluate | Score tools on 5 filters | Avoid tool bloat, ensure fit | MVP |
| 9. Finding Tools | 1:35-2:00 | Assess privacy implications | Evaluate | Flag inappropriate tools | Protect client data | MVP |
| 10. AI Security & Fraud | 2:10-2:40 | Detect AI-generated fraud | Evaluate | 6-item quiz on fakes | Protect clients and transactions | MVP |
| 10. AI Security & Fraud | 2:10-2:40 | Apply verification protocol | Apply | Describe wire change workflow | Prevent fraud losses | MVP |
| 10. AI Security & Fraud | 2:10-2:40 | Identify manipulation red flags | Analyze | Spot manipulation in 4 demos | Catch deepfakes and doctored docs | MVP |
| 11. Desktop AI + Connectors | 2:40-3:25 | Use hotkey workflow | Apply | Complete 3 file workflows | Process PDFs, screenshots, photos | Enhancement |
| 11. Desktop AI + Connectors | 2:40-3:25 | Extract structured information | Apply | Pull 7 fields from file | Get data from unstructured sources | Enhancement |
| 11. Desktop AI + Connectors | 2:40-3:25 | Transform files to outputs | Apply | Generate summary/reply/tasks | Speed communication workflows | Enhancement |
| 12. Capstone Sprint | 3:25-3:55 | Synthesize complete AI workflow | Create | Build 5-part capstone pack | Create production-ready system | MVP |
| 12. Capstone Sprint | 3:25-3:55 | Create reusable AI assets | Create | Prompt, context, samples, metrics | Enable Monday implementation | MVP |
| 12. Capstone Sprint | 3:25-3:55 | Demonstrate compliance controls | Evaluate | Verification steps documented | Ensure professional standards | MVP |
| 13. Commitments | 3:55-4:00 | Commit to 48-hour implementation | Apply | Public verbal commitment | Start using AI immediately | MVP |
| 13. Commitments | 3:55-4:00 | Establish accountability partnership | Apply | Buddy contact exchange | Support sustained adoption | Enhancement |

**Priority Legend:**
- **MVP:** Must-achieve outcomes for course success
- **Enhancement:** Valuable but not critical for minimum viable competency
- **Future:** Advanced outcomes for post-workshop development

---

## Learning Outcomes Progression Map

### Cognitive Progression (Bloom's Taxonomy)

```
MORNING (9:00-12:00): FOUNDATION
├─ Remember/Understand (Levels 1-2)
│  ├─ Mental models and analogies
│  ├─ AI capabilities and limitations
│  └─ Basic prompting concepts
│
└─ Apply (Level 3)
   ├─ Use templates for first AI outputs
   ├─ Follow prompting checklist
   └─ Iterate on basic content

AFTERNOON (1:00-4:00): COMPETENCE & TRANSFER
├─ Analyze/Evaluate (Levels 4-5)
│  ├─ Job prioritization and tool selection
│  ├─ Fraud detection and compliance
│  └─ Quality assessment of AI outputs
│
└─ Create (Level 6)
   ├─ Custom prompts and context cards
   ├─ Complete AI-enhanced workflows
   └─ Measurement and improvement systems
```

### Skill Progression (Scaffolded Complexity)

```
PHASE 1: CONFIDENCE BUILDING (9:00-10:35)
├─ Success in first 15 minutes (demo follow-along)
├─ Simple template-based tasks (fill-in-blank prompts)
├─ High success rate builds belief
└─ Outcome: "I can do this"

PHASE 2: COMPETENCE DEVELOPMENT (10:35-2:40)
├─ Progressive skill layers (prompting → context → iteration)
├─ Multiple practice cycles with feedback
├─ Increasing autonomy (guided → collaborative → independent)
└─ Outcome: "I'm getting good at this"

PHASE 3: TRANSFER PREPARATION (2:40-4:00)
├─ Real work integration (own properties and workflows)
├─ Problem-solving and troubleshooting
├─ Complete production-ready systems
└─ Outcome: "I'll use this Monday"
```

### Application Progression (Real Estate Context)

```
DEPTH 1: SINGLE-TASK AUTOMATION
├─ Generate one listing description
├─ Rewrite one client email
└─ Skills: Basic prompting, template usage

DEPTH 2: MULTI-TASK WORKFLOWS
├─ Create listing package (description + social + email)
├─ Integrate context card across uses
└─ Skills: Context engineering, consistency, iteration

DEPTH 3: SYSTEMATIC PROCESS DESIGN
├─ Build complete pilot job system
├─ Document reusable workflows
├─ Measure and optimize
└─ Skills: Synthesis, quality control, continuous improvement
```

---

## Measurement Strategy

### During-Workshop Assessment (Formative)

**Purpose:** Guide instruction and provide immediate feedback to support learning

**Methods:**

1. **Observation During Practice**
   - Instructor circulates during all hands-on exercises
   - Note common struggles and address to whole group
   - Provide just-in-time individual coaching
   - Frequency: Continuous during 70% practice time

2. **Exit Tickets (End of Each Module)**
   - 1-2 quick reflection questions on index card or digital form
   - Examples: "What's still confusing?" "What will you try first?"
   - Informs next module adjustments
   - Frequency: 5 major modules

3. **Think-Pair-Share**
   - Individual reflection → partner discussion → group sharing
   - Example: "How would AI help your biggest time drain?"
   - Provides insight into understanding without formal test
   - Frequency: 3-4 times throughout day

4. **Live Polling & Thumbs Checks**
   - Quick confidence checks: thumbs up/sideways/down
   - Tool selection preferences, concept clarity
   - Immediate visual feedback to instructor
   - Frequency: After new concept introduction

5. **Peer Review During Exercises**
   - Partners evaluate each other's work using rubrics
   - Builds evaluation skills and provides feedback
   - Example: "Check partner's prompt for 5 required elements"
   - Frequency: Major practice exercises (prompting, context engineering)

6. **Self-Assessment Checklists**
   - Participants evaluate own work against criteria
   - Builds metacognition and independence
   - Example: "My output includes accurate details [✓], appropriate length [✓]"
   - Frequency: Provided for all major deliverables

**Success Indicators (Formative):**
- 80%+ thumbs up/sideways (not down) on confidence checks
- Common struggles identified and addressed within 10 minutes
- Peer feedback reveals growing evaluation sophistication
- Exit tickets show decreasing confusion over day

---

### End-of-Workshop Assessment (Summative)

**Purpose:** Verify learning objectives achieved and readiness for workplace application

**Methods:**

1. **Capstone Pack Performance Task (3:25-3:55)**
   - **What:** Create complete AI workflow for 1 pilot job
   - **Components:** Prompt file, context card, 2 sample inputs, 2 verified outputs, measurement plan
   - **Rubric:** 10 points total
     - Clarity (2): Prompt is specific and actionable
     - Context (2): Voice & tactics card is complete and specific
     - Safety/Compliance (2): Verification steps documented, Fair Housing awareness
     - Measurable Outcome (2): Metrics track time saved and quality proxy
     - Repeatability (2): System is reusable and documented
   - **Success:** 90%+ score ≥7/10

2. **Fraud Detection Quiz (2:10-2:40)**
   - **What:** 6-item checklist on realistic fraud scenarios
   - **Scenarios:** Text phishing, voice cloning, image manipulation, document tampering
   - **Format:** Multiple choice or short answer
   - **Success:** 80%+ pass with ≥5/6 correct

3. **Scenario-Based Tool Selection (1:35-2:00)**
   - **What:** Match 5 real estate jobs to appropriate AI tools
   - **Criteria:** Job-to-be-done, privacy, cost, integration, time savings
   - **Format:** Decision tree walkthrough with written justification
   - **Success:** 80%+ correctly select tools for 4/5 scenarios

4. **Prompt Quality Rubric (Multiple Drills)**
   - **What:** Evaluate prompts for 5 elements (audience, channel, facts, style, exclusions)
   - **Format:** Peer-reviewed using checklist
   - **Success:** 85%+ prompts include all 5 elements by end of day

5. **Live Performance Demonstration**
   - **What:** Complete 3 file-type workflows (PDF, image, screenshot)
   - **Assessment:** Successfully extract information and generate usable output
   - **Success:** 75%+ complete all 3 workflows accurately

**Success Indicators (Summative):**
- 90%+ produce usable AI-generated content
- 80%+ pass compliance and fraud detection assessments
- 85%+ create complete, specific context cards
- 90%+ have actionable 48-hour implementation plan

---

### Post-Workshop Transfer Assessment (30-90 Days)

**Purpose:** Measure sustained behavior change and real-world impact

**Methods:**

1. **30-Day Adoption Survey (Email/Digital)**
   - **Questions:**
     - Which AI tools have you used in last 30 days?
     - How often? (Daily / 2-3x week / Weekly / Tried once / Never)
     - Which tasks are you automating? (List from workshop)
     - Time saved per week? (Self-reported estimate)
     - Quality improvement noticed? (Likert scale)
     - Obstacles encountered? (Open-ended)
     - Additional support needed? (Open-ended)
   - **Success Target:** 60%+ using AI at least weekly

2. **Manager/Broker Observation Report**
   - **Questions:**
     - How many team members are using AI tools?
     - For which tasks? (Marketing, client communication, transaction management, etc.)
     - Quality changes observed? (Improved/Same/Declined)
     - Client feedback changes? (Positive/Neutral/Negative)
     - Support needed from brokerage?
   - **Success Target:** Managers report visible behavior change in 50%+ participants

3. **Work Product Review (Sample Collection)**
   - **What:** Request 2-3 AI-assisted outputs from volunteers
   - **Review:** Assess appropriate use, quality, compliance, brand alignment
   - **Feedback:** Provide individualized coaching
   - **Success Target:** 80%+ submitted work meets professional standards

4. **Success Story Collection**
   - **What:** Invite participants to share wins (time saved, deals closed, client feedback)
   - **Format:** Short testimonial (text, video, or interview)
   - **Use:** Reinforce positive outcomes, create social proof for future cohorts
   - **Success Target:** 10+ documented success stories within 90 days

5. **Follow-Up Office Hours Attendance**
   - **What:** Track participation in post-workshop support sessions
   - **Indicator:** High attendance = ongoing engagement and questions
   - **Success Target:** 30%+ attend at least one office hours session

6. **Accountability Partnership Check-Ins**
   - **What:** Survey buddy pairs on connection frequency
   - **Questions:** Did you connect? How often? What was helpful?
   - **Success Target:** 50%+ buddy pairs made contact at least twice

**Transfer Success Metrics:**

| Metric | 30-Day Target | 90-Day Target | Measurement Method |
|--------|---------------|---------------|--------------------|
| Using AI at least weekly | 60% | 50% | Self-report survey |
| Time saved per week | 3 hours avg | 5 hours avg | Self-report survey |
| Confidence improvement | +2 points (1-5 scale) | +2.5 points | Pre/post comparison |
| Recommend to colleagues | 70% | 75% | NPS-style question |
| Manager-observed adoption | 50% | 60% | Manager report |
| Quality improvement | 65% report improvement | 70% | Self-report + manager |
| Continued tool use | 60% active | 40% active | Survey + analytics |

---

### Course Effectiveness Metrics (Program Evaluation)

**Immediate (End of Day 1):**
- Participant satisfaction: 85%+ rate course 4-5/5 stars
- Learning confidence: 80%+ feel confident to use AI (4-5/5)
- Relevance rating: 90%+ found content directly applicable
- Likelihood to recommend: 80%+ NPS promoters (9-10/10)

**30-Day (Behavior Change):**
- Active adoption rate: 60%+ using AI weekly
- Pilot job implementation: 70%+ implemented at least 1 of 2 pilots
- Time savings achieved: 3+ hours/week average
- Tool stack maintained: 75%+ kept stack to 1-3 tools (avoided bloat)

**90-Day (Business Impact):**
- Sustained adoption: 40%+ daily or near-daily use
- Measurable ROI: 50%+ report quantifiable time/money savings
- Quality improvements: 60%+ report client feedback or engagement improvement
- Expanded application: 40%+ using AI for tasks beyond workshop scope
- Brokerage impact: 25%+ shared knowledge with team members

**Success Definition:**

The AI Acceleration course is successful if:
1. **Immediate Competency:** 90%+ leave workshop able to generate professional AI content independently
2. **Short-Term Adoption:** 60%+ are actively using AI tools 30 days later
3. **Long-Term Integration:** 40%+ have integrated AI into daily workflows by 90 days
4. **Business Impact:** Participants report average 5 hours/week time savings and maintain professional quality standards
5. **Referrals & Expansion:** 70%+ would recommend course, leading to repeat bookings for WCAR

---

## Assessment Rubrics & Tools

### Capstone Pack Rubric (10 Points Total)

| Criterion | Unsatisfactory (0) | Developing (1) | Proficient (2) | Exemplary (3)* |
|-----------|-------------------|----------------|----------------|----------------|
| **Clarity** (2 pts) | Prompt is vague or missing key elements | Prompt includes some elements but lacks specificity | Prompt is specific with all required elements | N/A |
| **Context** (2 pts) | Context card incomplete or generic | Context card complete but lacks specificity | Context card complete with specific voice, objections, local details | N/A |
| **Safety/Compliance** (2 pts) | No verification steps or compliance awareness | Verification mentioned but not systematic | Documented verification workflow and compliance checks | N/A |
| **Measurable Outcome** (2 pts) | No metrics defined | Vague metrics (e.g., "save time") | Specific metrics (minutes saved, quality proxy tracked) | N/A |
| **Repeatability** (2 pts) | System not documented for reuse | Documented but unclear/incomplete | Fully documented, reusable system ready for Monday | N/A |

*Note: Maximum 2 points per criterion (no 3-point tier)

**Scoring:**
- **9-10 points:** Exceptional - Ready for immediate implementation and scaling
- **7-8 points:** Proficient - Ready for Monday use with minor refinement
- **5-6 points:** Developing - Needs additional work before production use
- **0-4 points:** Needs significant revision and additional practice

---

### Prompting Quality Checklist (5 Elements)

**Participant Name:** ________________
**Exercise:** ________________
**Reviewer:** ________________

| Element | Present? | Example/Evidence |
|---------|----------|------------------|
| **Audience:** Who is this for? | ☐ Yes  ☐ No | |
| **Channel:** Where will this appear? | ☐ Yes  ☐ No | |
| **Facts:** What essential information is provided? | ☐ Yes  ☐ No | |
| **Style:** What tone/voice/constraints specified? | ☐ Yes  ☐ No | |
| **Exclusions:** What should AI NOT include? | ☐ Yes  ☐ No | |

**Total:** ___/5 elements present

**Feedback:**

**Strengths:**

**Improvements:**

---

### Fraud Detection Quiz (6 Scenarios)

**Instructions:** For each scenario, identify the red flags and describe the correct verification action.

**Scenario 1: Wire Instruction Email**
An email from "titlecompany@gmail.com" with urgent wire transfer instructions arrives Friday at 5 PM, requesting immediate payment to close Monday.

**Red flags:** ________________
**Correct action:** ________________
**Pass criteria:** Identifies suspicious domain + urgency tactic; describes calling known title company number

**Scenario 2: Broker Voicemail**
You receive a voicemail from someone claiming to be your broker asking you to show a property immediately. Voice sounds right but they're asking for lockbox code via text.

**Red flags:** ________________
**Correct action:** ________________
**Pass criteria:** Identifies unusual request method; describes calling broker's known number to verify

**Scenario 3: Listing Photo**
A competitor's listing shows a beautifully landscaped yard that looks suspiciously perfect. The grass color is uniform but shadows seem inconsistent.

**Red flags:** ________________
**Correct action:** ________________
**Pass criteria:** Identifies potential virtual enhancement; describes disclosure requirements if using AI staging

**Scenario 4: Purchase Agreement Amendment**
A client forwards a "signed" addendum with changed terms. The signature looks right, but the formatting seems off from the original.

**Red flags:** ________________
**Correct action:** ________________
**Pass criteria:** Identifies document inconsistency; describes requesting original from known source

**Scenario 5: Client Text Message**
Your seller client texts asking to discuss urgent price reduction. The number matches their contact, but the writing style seems different from their usual messages.

**Red flags:** ________________
**Correct action:** ________________
**Pass criteria:** Identifies style inconsistency; describes calling client to verify before responding

**Scenario 6: Market Report Email**
You receive a detailed market analysis from an unfamiliar sender claiming to be a new data service offering free reports. It asks you to create an account with email/password.

**Red flags:** ________________
**Correct action:** ________________
**Pass criteria:** Identifies phishing attempt; describes avoiding credential sharing and verifying sender legitimacy

**Scoring:** ≥5/6 correct = Pass

---

### Context Card Completeness Checklist

**Participant Name:** ________________

| Component | Completeness | Specificity | Notes |
|-----------|--------------|-------------|-------|
| **Voice Pillars** (3 attributes) | ☐ 0-1  ☐ 2  ☐ 3+ | ☐ Generic  ☐ Specific | |
| **Taboo Phrases** (5 items) | ☐ 0-2  ☐ 3-4  ☐ 5+ | ☐ Generic  ☐ Specific | |
| **CTA Hierarchy** (preferred actions) | ☐ Missing  ☐ Present | ☐ Generic  ☐ Specific | |
| **Buyer Objections + Rebuttals** (5 pairs) | ☐ 0-2  ☐ 3-4  ☐ 5+ | ☐ Generic  ☐ Specific | |
| **Seller Objections + Rebuttals** (5 pairs) | ☐ 0-2  ☐ 3-4  ☐ 5+ | ☐ Generic  ☐ Specific | |
| **Micro-Geography Details** (3+ items) | ☐ 0-1  ☐ 2  ☐ 3+ | ☐ Generic  ☐ Specific | |
| **Formatting Preferences** | ☐ Missing  ☐ Present | ☐ Vague  ☐ Specific | |
| **Compliance Notes** | ☐ Missing  ☐ Present | ☐ Vague  ☐ Specific | |

**Overall Assessment:**
- ☐ Incomplete (missing major components)
- ☐ Complete but generic (needs more specificity)
- ☐ Complete and specific (ready to use)

**Feedback:**

---

## Continuous Improvement Process

**Post-Course Review Cycle:**

1. **Immediate (Week 1):**
   - Review participant feedback from end-of-day surveys
   - Analyze which modules showed lower confidence scores
   - Identify technical issues or pacing problems
   - Note frequently asked questions for FAQ addition

2. **30-Day Review:**
   - Analyze adoption survey results
   - Identify common barriers to implementation
   - Review which tools/techniques had highest adoption
   - Collect success stories and failure patterns

3. **90-Day Review:**
   - Assess long-term transfer success
   - Interview subset of participants for deep insights
   - Measure business impact metrics
   - Determine ROI for WCAR and participants

4. **Course Iteration:**
   - Adjust module time allocation based on observed needs
   - Update examples and demos with fresh real estate scenarios
   - Refresh tool recommendations as AI landscape evolves
   - Incorporate participant success stories into future cohorts

**Document Control:**
- This learning outcomes document should be reviewed quarterly
- Update Bloom's taxonomy alignment as course evolves
- Refine assessment rubrics based on observed performance patterns
- Maintain version history for continuous improvement tracking

---

## Appendix A: Bloom's Taxonomy Reference

### Cognitive Levels (Revised Taxonomy)

**Level 1: Remember**
- **Definition:** Recall facts and basic concepts
- **Action Verbs:** Define, list, recall, recognize, identify, name
- **Example:** List the 5 elements of an effective prompt

**Level 2: Understand**
- **Definition:** Explain ideas or concepts
- **Action Verbs:** Describe, explain, summarize, interpret, classify
- **Example:** Explain why AI is a "word engine" not a "truth engine"

**Level 3: Apply**
- **Definition:** Use information in new situations
- **Action Verbs:** Execute, implement, use, demonstrate, solve
- **Example:** Use prompting checklist to generate listing description

**Level 4: Analyze**
- **Definition:** Draw connections among ideas
- **Action Verbs:** Compare, contrast, categorize, examine, differentiate
- **Example:** Categorize real estate tasks as strong/weak AI fits

**Level 5: Evaluate**
- **Definition:** Justify a decision or course of action
- **Action Verbs:** Assess, judge, critique, prioritize, verify
- **Example:** Evaluate job candidates for AI pilot using selection criteria

**Level 6: Create**
- **Definition:** Produce new or original work
- **Action Verbs:** Design, construct, develop, formulate, synthesize
- **Example:** Design complete AI-enhanced workflow for listing preparation

---

## Appendix B: Adult Learning Principles Application

**Knowles' Six Principles in AI Acceleration:**

1. **Need to Know**
   - Application: Open with competitive pressure and time-savings statistics
   - Evidence: 92% of CRE teams piloting AI; 5-10 hours/week savings documented

2. **Self-Directed Learning**
   - Application: Participants choose own use cases and pilot jobs
   - Evidence: Job scan exercise, personalized capstone sprint

3. **Experience-Based**
   - Application: Use participants' actual listings and properties
   - Evidence: All practice exercises use real content, not hypotheticals

4. **Readiness to Learn**
   - Application: Address immediate pain points (time drains, client expectations)
   - Evidence: Opening pulse captures live priorities to address

5. **Orientation to Learning**
   - Application: Organize by tasks (listings, emails, fraud detection) not AI theory
   - Evidence: Module structure follows job-to-be-done framework

6. **Motivation**
   - Application: Emphasize professional mastery and competitive advantage
   - Evidence: Frame as augmentation (more time for relationships) not replacement

---

## Appendix C: Assessment Alignment to Learning Outcomes

**Ensuring Valid Assessment:**

Every learning outcome must have:
1. **Clear success criteria:** What does "successful" look like?
2. **Appropriate assessment method:** Match method to Bloom's level
3. **Authentic context:** Assess in realistic real estate scenarios
4. **Formative feedback:** Support learning during practice
5. **Summative verification:** Confirm competency before moving forward

**Assessment Type by Bloom's Level:**

- **Remember/Understand:** Verbal explanation, teach-back, spot-the-difference
- **Apply:** Performance task, demonstration, workflow completion
- **Analyze/Evaluate:** Scenario-based decisions, rubric-based critique, prioritization exercise
- **Create:** Original work product, complete system design, synthesis task

**Alignment Check Questions:**
1. Does this assessment actually measure the stated outcome?
2. Is the assessment method appropriate for the cognitive level?
3. Could a participant pass this assessment without mastering the outcome?
4. Does the assessment provide actionable feedback for improvement?
5. Is the assessment realistic to complete within time constraints?

---

**Document End**

**Next Steps:**
1. Share with WCAR for feedback and approval
2. Use outcomes to design detailed lesson plans and materials
3. Create assessment instruments (rubrics, quizzes, checklists)
4. Develop participant workbook aligned to outcomes
5. Train any co-facilitators on outcome-based instruction approach

**Version History:**
- v1.0 (2025-11-12): Initial learning outcomes architecture based on course outline, run-of-show, industry research, and pedagogy best practices
